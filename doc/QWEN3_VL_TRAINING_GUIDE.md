# Qwen3-VL-4B LoRAå¾®è°ƒå®Œå…¨æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3åˆ†é’Ÿä¸Šæ‰‹ï¼‰

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# ç¡®ä¿å·²å®‰è£…LLaMA-Factory
cd /home/worku22/LLaMA-Factory
pip install -e ".[torch,metrics]"
```

### 2. ä¸€é”®å¯åŠ¨è®­ç»ƒ
```bash
# åŸºç¡€è®­ç»ƒå‘½ä»¤
llamafactory-cli train examples/train_lora/qwen3_vl_4b_lora_sft.yaml

# æˆ–ä½¿ç”¨Pythonç›´æ¥è¿è¡Œ
python src/train.py examples/train_lora/qwen3_vl_4b_lora_sft.yaml
```

---

## âš¡ é€Ÿåº¦ä¼˜åŒ–å…¨æ”»ç•¥

### æ ¸å¿ƒä¼˜åŒ–å‚æ•°è¯´æ˜

| å‚æ•° | ä½œç”¨ | æ¨èå€¼ | è¯´æ˜ |
|------|------|--------|------|
| `overwrite_cache` | ç¼“å­˜å¤ç”¨ | `false` | **é¦–è¦ä¼˜åŒ–é¡¹**ï¼Œå…³é—­åå¤ç”¨tokenizerç¼“å­˜ |
| `preprocessing_num_workers` | é¢„å¤„ç†å¹¶è¡Œ | CPUæ ¸å¿ƒæ•°Ã—70% | 16æ ¸CPUè®¾ä¸º12 |
| `dataloader_num_workers` | æ•°æ®åŠ è½½å¹¶è¡Œ | 4-8 | è¿‡å¤§å¯èƒ½OOM |
| `streaming` | æµå¼åŠ è½½ | å°æ•°æ®é›†false | >100ä¸‡æ ·æœ¬å¼€å¯ |
| `image_max_pixels` | å›¾åƒåˆ†è¾¨ç‡ | 262144(512Ã—512) | é™ä½å¯åŠ é€Ÿä½†å½±å“è´¨é‡ |

### åœºæ™¯åŒ–é…ç½®æ¨è

#### åœºæ™¯1ï¼šå°æ•°æ®é›†ï¼ˆ<1ä¸‡æ¡ï¼‰- è¿½æ±‚ç®€å•å¿«é€Ÿ
```yaml
streaming: false
overwrite_cache: false
preprocessing_num_workers: 8
dataloader_num_workers: 2
```

#### åœºæ™¯2ï¼šä¸­ç­‰æ•°æ®é›†ï¼ˆ1-100ä¸‡æ¡ï¼‰- å¹³è¡¡é€Ÿåº¦å’Œå†…å­˜
```yaml
streaming: false
overwrite_cache: false
preprocessing_num_workers: 16
dataloader_num_workers: 4
preprocessing_batch_size: 2000
tokenized_path: ./cache/my_dataset  # æŒ‡å®šç¼“å­˜è·¯å¾„
```

#### åœºæ™¯3ï¼šå¤§è§„æ¨¡æ•°æ®é›†ï¼ˆ>100ä¸‡æ¡ï¼‰- é˜²æ­¢OOM
```yaml
streaming: true
overwrite_cache: false
preprocessing_num_workers: 16
dataloader_num_workers: 4
buffer_size: 65536
preprocessing_batch_size: 4000
mix_strategy: interleave_under
```

---

## ğŸ“ æ•°æ®é›†å‡†å¤‡

### 1. æ•°æ®æ ¼å¼ç¤ºä¾‹
åœ¨ `data/` ç›®å½•ä¸‹åˆ›å»ºä½ çš„æ•°æ®é›†JSONæ–‡ä»¶ï¼š

```json
[
  {
    "messages": [
      {"role": "user", "content": "<image>è¯·æè¿°è¿™å¼ å›¾ç‰‡"},
      {"role": "assistant", "content": "è¿™æ˜¯ä¸€å¼ ..."}
    ],
    "images": ["path/to/image1.jpg"]
  }
]
```

### 2. æ³¨å†Œæ•°æ®é›†
ç¼–è¾‘ `data/dataset_info.json`ï¼Œæ·»åŠ ï¼š

```json
{
  "my_dataset": {
    "file_name": "my_dataset.json",
    "formatting": "sharegpt",
    "columns": {
      "messages": "messages",
      "images": "images"
    }
  }
}
```

### 3. ä¿®æ”¹é…ç½®æ–‡ä»¶
```yaml
dataset: my_dataset  # ä½¿ç”¨ä½ æ³¨å†Œçš„æ•°æ®é›†åç§°
```

---

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

### å•å¡è®­ç»ƒ
```bash
CUDA_VISIBLE_DEVICES=0 llamafactory-cli train examples/train_lora/qwen3_vl_4b_lora_sft.yaml
```

### å¤šå¡è®­ç»ƒï¼ˆDDPï¼‰
```bash
CUDA_VISIBLE_DEVICES=0,1,2,3 llamafactory-cli train examples/train_lora/qwen3_vl_4b_lora_sft.yaml
```

### æŒ‡å®šå‚æ•°è¦†ç›–é…ç½®
```bash
llamafactory-cli train examples/train_lora/qwen3_vl_4b_lora_sft.yaml \
  --num_train_epochs 5 \
  --learning_rate 5e-5 \
  --output_dir saves/my_experiment
```

### æ–­ç‚¹ç»­è®­
```bash
llamafactory-cli train examples/train_lora/qwen3_vl_4b_lora_sft.yaml \
  --resume_from_checkpoint saves/qwen3_vl-4b/lora/sft/checkpoint-500
```

---

## ğŸ’¡ å¸¸è§é—®é¢˜è§£å†³

### Q1: TokenizeråŠ è½½æ…¢ï¼ˆ5-6åˆ†é’Ÿï¼‰
**åŸå› **ï¼šæ¯æ¬¡é‡æ–°å¤„ç†æ•°æ®  
**è§£å†³**ï¼š
```yaml
overwrite_cache: false  # å…³é”®ï¼
```

### Q2: å†…å­˜æº¢å‡º(OOM)
**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
per_device_train_batch_size: 1  # é™ä½batch size
gradient_accumulation_steps: 16  # å¢å¤§æ¢¯åº¦ç´¯ç§¯
image_max_pixels: 131072  # é™ä½å›¾åƒåˆ†è¾¨ç‡(256Ã—512)
streaming: true  # å¼€å¯æµå¼åŠ è½½
```

### Q3: è®­ç»ƒé€Ÿåº¦æ…¢
**æ£€æŸ¥æ¸…å•**ï¼š
1. ç¡®è®¤ä½¿ç”¨äº† `bf16: true`
2. æ£€æŸ¥GPUåˆ©ç”¨ç‡ï¼š`nvidia-smi -l 1`
3. å¢åŠ  `dataloader_num_workers`
4. é™ä½ `image_max_pixels`

### Q4: get_rope_index shape mismatch é”™è¯¯
**åŸå› **ï¼šcutoff_lenæˆªæ–­äº†è§†è§‰token  
**è§£å†³**ï¼šå¢å¤§cutoff_lenæˆ–é™ä½image_max_pixels
```yaml
cutoff_len: 4096  # å¢å¤§åºåˆ—é•¿åº¦
image_max_pixels: 131072  # æˆ–é™ä½å›¾åƒåˆ†è¾¨ç‡
```

---

## ğŸ“Š è®­ç»ƒç›‘æ§

### æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
```bash
tail -f saves/qwen3_vl-4b/lora/sft/trainer_log.jsonl
```

### æŸ¥çœ‹lossæ›²çº¿
è®­ç»ƒå®Œæˆåï¼Œlosså›¾åƒä¿å­˜åœ¨ï¼š
```
saves/qwen3_vl-4b/lora/sft/training_loss.png
```

### ä½¿ç”¨TensorBoard
```yaml
report_to: tensorboard
```
```bash
tensorboard --logdir saves/qwen3_vl-4b/lora/sft
```

---

## ğŸ¯ è®­ç»ƒå®Œæˆå

### åˆå¹¶LoRAæƒé‡
```bash
llamafactory-cli export \
  --model_name_or_path Qwen/Qwen3-VL-4B-Instruct \
  --adapter_name_or_path saves/qwen3_vl-4b/lora/sft \
  --template qwen3_vl \
  --export_dir models/qwen3_vl_merged
```

### æµ‹è¯•å¯¹è¯
```bash
llamafactory-cli chat \
  --model_name_or_path Qwen/Qwen3-VL-4B-Instruct \
  --adapter_name_or_path saves/qwen3_vl-4b/lora/sft \
  --template qwen3_vl
```

---

## ğŸ“‹ é…ç½®å‚æ•°é€ŸæŸ¥è¡¨

### å¿…é¡»é…ç½®
| å‚æ•° | è¯´æ˜ |
|------|------|
| `model_name_or_path` | æ¨¡å‹è·¯å¾„ |
| `dataset` | æ•°æ®é›†åç§° |
| `template` | å¯¹è¯æ¨¡æ¿ï¼ˆqwen3_vlï¼‰ |
| `output_dir` | è¾“å‡ºç›®å½• |

### é€Ÿåº¦ç›¸å…³
| å‚æ•° | é»˜è®¤å€¼ | åŠ é€Ÿå»ºè®® |
|------|--------|----------|
| `overwrite_cache` | true | **æ”¹ä¸ºfalse** |
| `preprocessing_num_workers` | 1 | æ”¹ä¸º16 |
| `bf16` | false | **æ”¹ä¸ºtrue** |
| `image_max_pixels` | 768Ã—768 | å¯é™è‡³512Ã—512 |

### å†…å­˜ç›¸å…³
| å‚æ•° | OOMæ—¶è°ƒæ•´ |
|------|-----------|
| `per_device_train_batch_size` | é™ä½ä¸º1 |
| `gradient_accumulation_steps` | å¢å¤§ |
| `cutoff_len` | é™ä½ |
| `streaming` | æ”¹ä¸ºtrue |

---

## ğŸ‰ ç¥ä½ è®­ç»ƒé¡ºåˆ©ï¼

å¦‚æœ‰é—®é¢˜ï¼Œå¯ä»¥ï¼š
1. æŸ¥çœ‹ `saves/*/trainer_log.jsonl` æ—¥å¿—
2. æ£€æŸ¥GPUå†…å­˜ï¼š`nvidia-smi`
3. è°ƒæ•´é…ç½®å‚æ•°é‡è¯•
