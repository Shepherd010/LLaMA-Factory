# VLM API å¿«é€Ÿé…ç½®æŒ‡å—

## ğŸ¯ ä¸‰å¥è¯æ€»ç»“

1. **taskgenerate/** = AI2THOR åœºæ™¯çš„ **é™æ€æ•°æ®åº“**ï¼ˆåªæœ‰å¯¹è±¡ä¿¡æ¯ï¼‰
2. **TaskGenerate.py** = çº¯ **é€»è¾‘è§„åˆ™** ç”Ÿæˆä»»åŠ¡æ¨¡æ¿ï¼ˆ**æ— éœ€VLM**ï¼‰
3. **o1StyleGenerate.py** = è°ƒç”¨VLM **ç”Ÿæˆæ€ç»´è½¨è¿¹**ï¼ˆ**éœ€è¦VLM**ï¼‰

---

## é…ç½®æ­¥éª¤

### 1. è·å– API Key

#### é€‰é¡¹Aï¼šä½¿ç”¨ OpenAIï¼ˆChatGPTï¼‰
1. è®¿é—® https://platform.openai.com/api-keys
2. åˆ›å»ºæ–° API Key
3. å¤åˆ¶ keyï¼ˆæ ¼å¼: `sk-proj-xxxxx`ï¼‰

#### é€‰é¡¹Bï¼šä½¿ç”¨å…¶ä»–æœåŠ¡
- **Claude**: https://console.anthropic.com/
- **Qwen**: https://dashscope.console.aliyun.com/
- **æœ¬åœ°æ¨¡å‹**: LLaMAã€Mistral ç­‰

---

### 2. æ·»åŠ  API Key

**æ–‡ä»¶**: `data_engine/VLMCallapi_keys.py`

```python
# æ–¹æ¡ˆ1ï¼šç›´æ¥æ·»åŠ ï¼ˆä¸å®‰å…¨ï¼Œè°¨æ…æäº¤ï¼‰
api_keys = [
    "sk-proj-your-openai-key-here",
]

# æ–¹æ¡ˆ2ï¼šä»ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰
import os
api_keys = [
    os.getenv("OPENAI_API_KEY"),
]

# æ–¹æ¡ˆ3ï¼šè¯»å–é…ç½®æ–‡ä»¶ï¼ˆæœ€å®‰å…¨ï¼‰
import json
with open("api_config.json", "r") as f:
    config = json.load(f)
api_keys = config["keys"]
```

**è®¾ç½®ç¯å¢ƒå˜é‡**ï¼ˆLinux/Macï¼‰ï¼š
```bash
export OPENAI_API_KEY="sk-proj-xxxxx"
```

**è®¾ç½®ç¯å¢ƒå˜é‡**ï¼ˆWindows PowerShellï¼‰ï¼š
```powershell
$env:OPENAI_API_KEY="sk-proj-xxxxx"
[Environment]::SetEnvironmentVariable("OPENAI_API_KEY", "sk-proj-xxxxx", "User")
```

---

### 3. ä¿®æ”¹ VLM æ¨¡å‹

**æ–‡ä»¶**: `data_engine/o1StyleGenerate.py`

**æœç´¢ä¸»ç¨‹åºéƒ¨åˆ†**ï¼š
```python
if __name__=="__main__":
    model = "gpt-4o-2024-11-20"  # â† æ”¹è¿™è¡Œ
```

**æ”¯æŒçš„æ¨¡å‹**ï¼š
```python
model = "gpt-4-turbo"            # GPT-4 Turbo
model = "gpt-4o"                 # GPT-4O
model = "gpt-4o-mini"            # GPT-4O Miniï¼ˆä¾¿å®œï¼‰
model = "claude-3-opus"          # Claudeï¼ˆéœ€æ”¹APIï¼‰
model = "qwen-vl-max"            # é€šä¹‰åƒé—®ï¼ˆéœ€æ”¹APIï¼‰
```

---

### 4. ä¿®æ”¹ API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰

**æ–‡ä»¶**: `data_engine/vlmCall.py`

```python
# å½“å‰ï¼ˆç¬¬ä¸‰æ–¹å…¼å®¹ï¼‰
conn = http.client.HTTPSConnection("us.ifopen.ai")

# æ”¹ä¸ºå®˜æ–¹ OpenAI
conn = http.client.HTTPSConnection("api.openai.com")

# æ”¹ä¸ºæœ¬åœ°éƒ¨ç½²ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
conn = http.client.HTTPSConnection("localhost:8000")
```

---

## æµ‹è¯•é…ç½®

### æµ‹è¯• API Key

åˆ›å»ºæ–‡ä»¶ `test_vlm.py`ï¼š

```python
from data_engine.vlmCall import VLMAPI
from PIL import Image
import requests

# 1. æµ‹è¯•APIè¿æ¥
llmapi = VLMAPI("gpt-4o-mini")  # ç”¨miniç‰ˆä¾¿å®œ

# 2. æµ‹è¯•æ–‡å­—è¯·æ±‚
try:
    response = llmapi.vlm_request(
        systext="You are a helpful assistant.",
        usertext="Say hello!"
    )
    print(f"âœ… APIè¿æ¥æˆåŠŸï¼å“åº”: {response}")
except Exception as e:
    print(f"âŒ APIé”™è¯¯: {e}")

# 3. æµ‹è¯•å›¾åƒè¯·æ±‚
try:
    # ä¸‹è½½æµ‹è¯•å›¾åƒ
    url = "https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg"
    img_path = "test_cat.jpg"
    img = Image.open(requests.get(url, stream=True).raw)
    img.save(img_path)
    
    response = llmapi.vlm_request(
        systext="Describe this image briefly.",
        usertext="What do you see?",
        image_path1=img_path
    )
    print(f"âœ… å›¾åƒå¤„ç†æˆåŠŸï¼å“åº”: {response[:100]}...")
except Exception as e:
    print(f"âŒ å›¾åƒå¤„ç†é”™è¯¯: {e}")
```

**è¿è¡Œ**ï¼š
```bash
cd embodied_reasoner
python test_vlm.py
```

---

## å¸¸è§é—®é¢˜æ’æŸ¥

### âŒ Error: "No module named 'vlmCall'"

**è§£å†³**ï¼š
```bash
cd data_engine
python -c "from vlmCall import VLMAPI; print('OK')"
```

### âŒ Error: "HTTP 401 Unauthorized"

**åŸå› **ï¼šAPI Key æ— æ•ˆæˆ–è¿‡æœŸ

**è§£å†³**ï¼š
1. æ£€æŸ¥ API Key æ ¼å¼ï¼ˆåº”è¯¥ä»¥ `sk-` å¼€å¤´ï¼‰
2. è®¿é—® https://platform.openai.com/api-keys é‡æ–°ç”Ÿæˆ
3. ç¡®ä¿è´¦æˆ·æœ‰è¶³å¤Ÿä½™é¢

### âŒ Error: "HTTP 429 Too Many Requests"

**åŸå› **ï¼šè¯·æ±‚é¢‘ç‡è¿‡é«˜æˆ–é¢åº¦é™åˆ¶

**è§£å†³**ï¼š
1. ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•
2. å‡çº§è´¦æˆ·é…é¢
3. ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆå¦‚ gpt-4o-miniï¼‰

### âŒ Error: "Connection refused"

**åŸå› **ï¼šæ— æ³•è¿æ¥åˆ° API æœåŠ¡å™¨

**è§£å†³**ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
3. å°è¯•æ”¹ç”¨ä»£ç†

### âŒ Error: "CUDA out of memory" (å¦‚æœä½¿ç”¨æœ¬åœ°æ¨¡å‹)

**åŸå› **ï¼šæ˜¾å­˜ä¸è¶³

**è§£å†³**ï¼š
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚ 7B è€Œé 70Bï¼‰
2. å¯ç”¨é‡åŒ–ï¼ˆint8, int4ï¼‰
3. å¢åŠ  GPU æ˜¾å­˜

---

## æˆæœ¬ä¼°ç®—

### OpenAI å®˜æ–¹ä»·æ ¼ï¼ˆ2024ï¼‰

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼ | ä½¿ç”¨åœºæ™¯ |
|------|---------|---------|----------|
| gpt-4-turbo | $0.01/1K tokens | $0.03/1K tokens | æœ€å¥½è´¨é‡ |
| gpt-4o | $0.005/1K tokens | $0.015/1K tokens | å¹³è¡¡ |
| gpt-4o-mini | $0.00015/1K tokens | $0.0006/1K tokens | **é¢„ç®—å‹å¥½** |

### ç”Ÿæˆ 1 æ¡è½¨è¿¹çš„æˆæœ¬

å‡è®¾ï¼š
- 10 æ­¥äº¤äº’
- æ¯æ­¥å¹³å‡ 500 token æ€ç»´è¾“å…¥ + 200 token è¾“å‡º
- 1 å¼ å›¾åƒ = ~300 token (base64)

```
æˆæœ¬ = (500 è¾“å…¥ Ã— 10 æ­¥ + 300 Ã— 10 å›¾ + 200 è¾“å‡º Ã— 10 æ­¥)
     = (5000 + 3000 + 2000) = 10,000 tokens
     
gpt-4o-mini: 10,000 Ã— ($0.00015 + $0.0006) = $0.0075 â‰ˆ 0.05 RMB
gpt-4-turbo: 10,000 Ã— ($0.01 + $0.03) = $0.4 â‰ˆ 3 RMB

ç”Ÿæˆ 9,300 æ¡è½¨è¿¹ï¼ˆå®Œæ•´æ•°æ®é›†ï¼‰ï¼š
gpt-4o-mini: $70 â‰ˆ 460 RMB
gpt-4-turbo: $3,720 â‰ˆ 24,000 RMB âš ï¸ è´µï¼
```

---

## ç”Ÿäº§ç¯å¢ƒå»ºè®®

### æ–¹æ¡ˆ 1ï¼šä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿ

**é˜¿é‡Œäº‘DashScope** (æ”¯æŒå›½å†…åŠ é€Ÿ)ï¼š
```python
# vlmCall.py
conn = http.client.HTTPSConnection("dashscope.aliyuncs.com")
headers = {
    'Authorization': 'Bearer ' + api_key,
    'Content-Type': 'application/json'
}
```

### æ–¹æ¡ˆ 2ï¼šä½¿ç”¨æœ¬åœ°å¼€æºæ¨¡å‹

```bash
# ä½¿ç”¨ ollama æˆ– vLLM
ollama run llava  # å¤šæ¨¡æ€æ¨¡å‹ï¼ˆæ”¯æŒå›¾åƒï¼‰

# æ”¹ vlmCall.py çš„ API ç«¯ç‚¹
conn = http.client.HTTPSConnection("localhost:11434")
```

### æ–¹æ¡ˆ 3ï¼šæ··åˆæ–¹æ¡ˆ

```python
# ä¾¿å®œçš„æ“ä½œç”¨ gpt-4o-mini
# å…³é”®æ“ä½œç”¨ gpt-4-turbo
# ç¦»çº¿æ“ä½œç”¨æœ¬åœ°æ¨¡å‹

def vlm_request(prompt_type, ...):
    if prompt_type == "simple_navigation":
        model = "gpt-4o-mini"  # ä¾¿å®œ
    elif prompt_type == "complex_reasoning":
        model = "gpt-4-turbo"  # å¥½
    elif prompt_type == "offline":
        model = "local_llava"  # å…è´¹
```

---

## éªŒè¯æ•°æ®ç”Ÿæˆç®¡é“

### éªŒè¯ 1ï¼šTaskGenerate å·¥ä½œæ­£å¸¸

```bash
cd data_engine
python TaskGenerate.py

# æ£€æŸ¥è¾“å‡º
ls single_search_task_metadata/
cat single_search_task_metadata/FloorPlan1.json | head -20
```

**é¢„æœŸè¾“å‡º**ï¼š
```json
[
  {
    "taskname": "Find the Apple in the room.",
    "tasktype": "single_search",
    "actions": [
      {"action": "navigate to", "objectId": "CounterTop|...", "reward": 1},
      {"action": "end", "reward": 1}
    ],
    "totalreward": 2
  }
]
```

### éªŒè¯ 2ï¼šo1StyleGenerate å·¥ä½œæ­£å¸¸

```bash
cd data_engine
python o1StyleGenerate.py

# æ£€æŸ¥è¾“å‡º
ls -la single_search/FloorPlan1/
cat single_search/FloorPlan1/trajectory_0.json | head -30
```

**é¢„æœŸè¾“å‡º**ï¼š
```json
{
  "scene": "FloorPlan1",
  "tasktype": "single_search",
  "taskname": "Find the Apple in the room.",
  "trajectory": [
    "<Observation> I see a kitchen with...",
    "<Thought> The apple is likely on...",
    "<Decision> I should navigate to...",
    ...
  ],
  "images": ["single_search/FloorPlan1/step_0.png", ...]
}
```

---

## ç›‘æ§å’Œè°ƒè¯•

### å¯ç”¨è¯¦ç»†æ—¥å¿—

**æ–‡ä»¶**: `vlmCall.py`

```python
# æ·»åŠ æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def vlm_request(self, ...):
    logger.debug(f"Sending request to {self.model}")
    logger.debug(f"Payload: {payload[:200]}...")
    # ...
    logger.debug(f"Response: {content[:200]}...")
```

### ç»Ÿè®¡ API è°ƒç”¨

```python
# åœ¨ o1StyleGenerate.py ä¸­æ·»åŠ 
class APICallTracker:
    def __init__(self):
        self.call_count = 0
        self.total_cost = 0.0
    
    def log_call(self, model, input_tokens, output_tokens):
        self.call_count += 1
        prices = {
            "gpt-4o-mini": (0.00015, 0.0006),
            "gpt-4-turbo": (0.01, 0.03),
        }
        in_p, out_p = prices.get(model, (0, 0))
        cost = (input_tokens * in_p + output_tokens * out_p) / 1000
        self.total_cost += cost
        print(f"Call #{self.call_count}: {model} - Cost: ${cost:.4f} (Total: ${self.total_cost:.2f})")

tracker = APICallTracker()
# tracker.log_call(model, input_tokens, output_tokens)
```

---

## ä¸‹ä¸€æ­¥

âœ… é…ç½®å®Œæˆåï¼š
1. è¿è¡Œ `test_vlm.py` éªŒè¯è¿æ¥
2. æ‰§è¡Œ `TaskGenerate.py` ç”Ÿæˆä»»åŠ¡
3. æ‰§è¡Œ `o1StyleGenerate.py` ç”Ÿæˆè½¨è¿¹
4. æ£€æŸ¥ `data/` æ–‡ä»¶å¤¹ä¸­çš„ç»“æœ

ğŸ“š æœ‰é—®é¢˜å‚è€ƒï¼š
- [OpenAI æ–‡æ¡£](https://platform.openai.com/docs)
- [é¡¹ç›® README](../README.md)
- [å®Œæ•´æ¶æ„æ–‡æ¡£](../PROJECT_ARCHITECTURE.md)
