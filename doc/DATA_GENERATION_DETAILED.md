# æ•°æ®ç”Ÿæˆç®¡é“è¯¦ç»†è§£æ

## é—®é¢˜æ ¸å¿ƒç†è§£

ä½ çš„ä¸‰ä¸ªå…³é”®é—®é¢˜ï¼š
1. **taskgenerate** åŒ…å«ä»€ä¹ˆï¼Ÿåœºæ™¯å®šä¹‰è¿˜æ˜¯åŠ¨ä½œå®šä¹‰ï¼Ÿ
2. **TaskGenerate.py** åšä»€ä¹ˆï¼Ÿéœ€è¦VLMå—ï¼Ÿ
3. **VLMé…ç½®**åœ¨å“ªé‡Œï¼Ÿå¦‚ä½•ä¿®æ”¹ï¼Ÿ

ç­”æ¡ˆï¼š**éƒ½ä¸ä¸€æ ·ï¼** è®©æˆ‘ä¸€å±‚å±‚å‰¥å¼€ã€‚

---

## ğŸ“ Layer 1: `taskgenerate/` - åœºæ™¯å…ƒæ•°æ®åº“

### æ–‡ä»¶ç»“æ„
```
taskgenerate/
â”œâ”€â”€ kitchens/
â”‚   â”œâ”€â”€ FloorPlan1/
â”‚   â”‚   â”œâ”€â”€ metadata.json        â† AI2THORåœºæ™¯çš„å®Œæ•´å…ƒæ•°æ®
â”‚   â”‚   â””â”€â”€ originPos.json       â† ä»£ç†åˆå§‹ä½ç½®
â”‚   â”œâ”€â”€ FloorPlan2/
â”‚   ...
â”œâ”€â”€ living_rooms/
â”œâ”€â”€ bedrooms/
â”œâ”€â”€ bathrooms/
â””â”€â”€ pick_up_and_put.json         â† ç‰©ä½“å…¼å®¹æ€§æ˜ å°„è¡¨
```

### metadata.json å†…å®¹ - **åªåŒ…å«åœºæ™¯é™æ€ä¿¡æ¯**

```json
{
  "agent": {
    "position": {"x": 1.5, "y": 0.901, "z": 0.5},
    "rotation": {"x": 0, "y": 0, "z": 0},
    "cameraHorizon": 0
  },
  "objects": [
    {
      "objectId": "CounterTop|00.08|01.15|00.00",
      "objectType": "CounterTop",
      "parentReceptacles": [],           â† çˆ¶å®¹å™¨(ä¸ºç©º=åœ¨åœ°æ¿ä¸Š)
      "pickupable": false,
      "receptacle": true,               â† æ˜¯å¦æ˜¯å®¹å™¨
      "openable": false,
      "isOpen": false,
      "toggleable": false,
      "isToggled": false,
      "visible": true,
      "axisAlignedBoundingBox": {...}
    },
    {
      "objectId": "Apple|00.47|01.15|00.48",
      "objectType": "Apple",
      "parentReceptacles": ["CounterTop|00.08|01.15|00.00"],  â† åœ¨è®¡æ•°å™¨ä¸Š
      "pickupable": true,               â† å¯æ‹¿èµ·
      "receptacle": false,
      "openable": false,
      "isOpen": false,
      "toggleable": false,
      "isToggled": false,
      "visible": true
    },
    {
      "objectId": "Fridge|00.20|00.00|01.50",
      "objectType": "Fridge",
      "parentReceptacles": [],
      "pickupable": false,
      "receptacle": true,
      "openable": true,                 â† å¯æ‰“å¼€
      "isOpen": false,                  â† åˆå§‹çŠ¶æ€å…³é—­
      "toggleable": false
    },
    {
      "objectId": "Egg|00.00|01.00|00.30",
      "objectType": "Egg",
      "parentReceptacles": ["Fridge|00.20|00.00|01.50"],  â† åœ¨å†°ç®±å†…
      "pickupable": true,
      "receptacle": false,
      "openable": false
    }
  ]
}
```

### pick_up_and_put.json å†…å®¹ - **ç‰©ä½“å…¼å®¹æ€§è§„åˆ™**

```json
[
  {
    "Apple": ["Pot", "Pan", "Bowl", "Microwave", "Fridge", "Plate", "SinkBasin", "CounterTop", "GarbageCan"]
  },
  {
    "Egg": ["Pot", "Pan", "Bowl", "Microwave", "Fridge", "Plate", "SinkBasin", "CounterTop", "GarbageCan"]
  },
  {
    "Bread": ["Pan", "Microwave", "Fridge", "Plate", "CounterTop", "GarbageCan"]
  }
]
```

**ä½œç”¨**ï¼šå®šä¹‰"è‹¹æœå¯ä»¥æ”¾åœ¨ä»€ä¹ˆå®¹å™¨é‡Œ"çš„è§„åˆ™ã€‚

---

## ğŸ”§ Layer 2: `TaskGenerate.py` - ä»»åŠ¡æ¨¡æ¿ç”Ÿæˆå™¨

### æœ¬è´¨
**å®Œå…¨ä¸éœ€è¦VLMï¼** è¿™æ˜¯çº¯ç²¹çš„ï¼š
- è¾“å…¥ï¼šåœºæ™¯å…ƒæ•°æ® (JSON)
- è¾“å‡ºï¼šä»»åŠ¡å…ƒæ•°æ® (JSON) + å…³é”®è¡ŒåŠ¨åºåˆ—
- å¤„ç†ï¼šé€»è¾‘è§„åˆ™ + éšæœºé‡‡æ ·

### æ ¸å¿ƒé€»è¾‘

#### ç¬¬1æ­¥ï¼šåŠ è½½åœºæ™¯å…ƒæ•°æ®
```python
# å®é™…ä»£ç æµç¨‹
metadata = load_json('taskgenerate/kitchens/FloorPlan1/metadata.json')
scene_objects = metadata['objects']  # è¿™ä¸ªåœºæ™¯æœ‰å“ªäº›ç‰©ä½“
```

#### ç¬¬2æ­¥ï¼šæ ¹æ® `task_type` æ‰§è¡Œå¯¹åº”æ–¹æ³•

```python
class TaskGenerate:
    def single_search(self, num=1):
        """
        ä»»åŠ¡ç±»å‹ï¼šå•ç›®æ ‡æœç´¢
        è§„åˆ™ï¼šæ‰¾ä¸€ä¸ªå¯æ‹¿èµ·çš„ç‰©ä½“
        """
        generate_task = []
        
        # éå†æ‰€æœ‰ç‰©ä½“
        for obj in scene_objects:
            # è¿‡æ»¤æ¡ä»¶1ï¼šç‰©ä½“å¯æ‹¿èµ·
            if not self.is_pickupable(obj):
                continue
            
            # è¿‡æ»¤æ¡ä»¶2ï¼šç‰©ä½“ä¸åœ¨åœ°æ¿ä¸Šï¼ˆåœ¨æŸä¸ªå®¹å™¨å†…ï¼‰
            if self.is_parent_floor_or_null(obj):
                continue
            
            # è¿‡æ»¤æ¡ä»¶3ï¼šç‰©ä½“çš„ç›´æ¥å®¹å™¨ä¸éœ€è¦æ‰“å¼€ï¼ˆä»¥æ±‚ç®€å•ï¼‰
            if self.is_parent_receptacle_openable(obj):
                continue
            
            # è¿‡æ»¤æ¡ä»¶4ï¼šç‰©ä½“çš„å®¹å™¨çš„å®¹å™¨æ˜¯åœ°æ¿ï¼ˆäºŒçº§æ·±åº¦é™åˆ¶ï¼‰
            if not self.is_grandparent_floor_or_null(obj):
                continue
            
            # âœ… æ¡ä»¶éƒ½æ»¡è¶³ â†’ ç”Ÿæˆä¸€ä¸ªä»»åŠ¡
            obj_type = obj['objectType']
            obj_id = obj['objectId']
            obj_parent_id = obj['parentReceptacles'][-1]
            obj_parent_type = obj_parent_id.split('|')[0]
            
            # éšæœºé€‰æ‹©è¡¨è¾¾æ–¹å¼
            expressions = [
                f"Find the {obj_type} in the room.",
                f"Locate the {obj_type} in the room.",
                ...
            ]
            task_name = random.choice(expressions)
            
            # æ„é€ ä»»åŠ¡ JSON
            task = {
                "taskname": task_name,                    # "Find the Apple in the room."
                "tasktype": "single_search",
                "metadatapath": "taskgenerate/kitchens/FloorPlan1/metadata.json",
                "actions": [
                    {
                        "action": "navigate to",
                        "objectId": "CounterTop|00.08|01.15|00.00",
                        "objectType": "CounterTop",
                        "reward": 1,
                        "relatedObject": ["CounterTop|00.08|01.15|00.00", "Apple|00.47|01.15|00.48"]
                    },
                    {
                        "action": "end",
                        "reward": 1,
                        "relatedObject": [...]
                    }
                ],
                "totalreward": 2
            }
            generate_task.append(task)
```

### 10ç§ä»»åŠ¡ç±»å‹è¯¦è§£

| ä»»åŠ¡ç±»å‹ | è§„åˆ™é€»è¾‘ | å…³é”®è¡ŒåŠ¨åºåˆ— | éš¾åº¦ |
|----------|---------|-------------|------|
| **single_search** | æ‰¾å¯æ‹¿èµ·çš„ç‰©ä½“ï¼Œåœ¨å®¹å™¨ä¸Š | navigate â†’ end | â­ |
| **single_search_from_closerep** | æ‰¾å¯æ‹¿èµ·çš„ç‰©ä½“ï¼Œåœ¨**å¯æ‰“å¼€çš„å®¹å™¨å†…** | navigate â†’ open â†’ end | â­â­ |
| **single_pickup** | æ‹¿èµ·ä¸€ä¸ªç‰©ä½“ | navigate â†’ pickup â†’ end | â­ |
| **single_pickup_from_closerep** | æ‹¿èµ·å®¹å™¨å†…çš„ç‰©ä½“ | navigate â†’ open â†’ pickup â†’ close â†’ end | â­â­â­ |
| **single_toggle** | åˆ‡æ¢å¼€å…³ï¼ˆç¯ç­‰ï¼‰ | navigate â†’ toggle â†’ end | â­ |
| **pickup_and_put** | æ‹¿èµ·ç‰©ä½“æ”¾åˆ°å¦ä¸€ä¸ªå®¹å™¨ | navigate â†’ pickup â†’ navigate â†’ put â†’ end | â­â­ |
| **pickup_from_closerep_and_put** | ä»å®¹å™¨æ‹¿å‡ºâ†’æ”¾åˆ°å¦ä¸€å®¹å™¨ | navigate â†’ open â†’ pickup â†’ close â†’ navigate â†’ put â†’ end | â­â­â­ |
| **pickup_and_put_in_closerep** | æ‹¿èµ·â†’æ”¾å…¥å¯æ‰“å¼€å®¹å™¨ | navigate â†’ pickup â†’ navigate â†’ open â†’ put â†’ end | â­â­â­ |
| **pickup_from_closerep_and_put_in_closerep** | å¤æ‚æ“ä½œ | navigate â†’ open â†’ pickup â†’ close â†’ navigate â†’ open â†’ put â†’ end | â­â­â­â­ |
| **ordered_pickup_two_object_and_put** | æœ‰åºçš„ä¸¤å¯¹è±¡è½¬ç§» | æœ€å¤æ‚çš„ç»„åˆ | â­â­â­â­â­ |

### è¾“å‡ºæ–‡ä»¶ä½ç½®
```
{task_type}_task_metadata/
â”œâ”€â”€ FloorPlan1.json    â† è¯¥åœºæ™¯çš„æ‰€æœ‰{task_type}ä»»åŠ¡
â”œâ”€â”€ FloorPlan2.json
â””â”€â”€ ...
```

**å…³é”®ç‚¹**ï¼š`TaskGenerate.py` **å®Œå…¨ä¸éœ€è¦VLM**ï¼å®ƒåªæ˜¯é€»è¾‘è¿‡æ»¤ + JSONç”Ÿæˆã€‚

---

## ğŸ¬ Layer 3: `o1StyleGenerate.py` - æ€ç»´è½¨è¿¹ç”Ÿæˆå™¨

### æœ¬è´¨
**å¿…é¡»éœ€è¦VLMï¼** è¿™æ˜¯ï¼š
- è¾“å…¥ï¼šä»»åŠ¡å…ƒæ•°æ® (æ¥è‡ªTaskGenerate) + è™šæ‹Ÿç¯å¢ƒ
- è¾“å‡ºï¼šObservation-Thought-Action è½¨è¿¹ + å›¾åƒ
- å¤„ç†ï¼šæ¨¡å‹æ¨ç† + ç¯å¢ƒæ‰§è¡Œ

### æ ¸å¿ƒæµç¨‹

```
1ï¸âƒ£ åŠ è½½ä»»åŠ¡
   task = load_json("single_search_task_metadata/FloorPlan1.json")
   task["taskname"] = "Find the Apple in the room."
   task["actions"] = [{"action":"navigate to", "objectId":"CounterTop|..."}, {"action":"end"}]

2ï¸âƒ£ åˆå§‹åŒ–ç¯å¢ƒ
   controller = Controller(scene="FloorPlan1", ...)
   rocAgent = RocAgent(controller)  # è™šæ‹Ÿæ™ºèƒ½ä½“

3ï¸âƒ£ å¾ªç¯æ‰§è¡Œï¼ˆå…³é”®ï¼ï¼‰
   for step in range(max_steps):
       
       a) è§‚å¯Ÿ
          image = capture_screenshot()
          observation_text = f"I'm in a kitchen. I can see: {visible_objects}"
       
       b) [FIRST TIME ONLY] è‡ªæˆ‘è§‚å¯Ÿ
          selfobs = VLM.generate(
              prompt="Describe the objects in front of you",
              image=image
          )
          # è¿”å›: "<Observation> I see a kitchen with a counter..."
          trajectory.append(selfobs)
       
       c) æ€ç»´ç”Ÿæˆ [éœ€è¦VLM]
          thinking = VLM.generate(
              system="You are a reasoning agent...",
              prompt=f"Task: {task['taskname']}. Current observation: {selfobs}. Next step?",
              images=[current_image, last_frame, initial_image]
          )
          # è¿”å›: "<Thought> The Apple is likely on the CounterTop...</Thought>"
          trajectory.append(thinking)
       
       d) è¡ŒåŠ¨å†³ç­– [éœ€è¦VLM]
          decision = VLM.generate(
              prompt="Based on your thought, what action should you take?",
              images=[...]
          )
          # è¿”å›: "navigate to CounterTop"
          action = parse_action(decision)
       
       e) æ‰§è¡Œè¡ŒåŠ¨
          rocAgent.execute(action)
          feedback = check_success()
       
       f) éªŒè¯/åæ€ [éœ€è¦VLM]
          if not feedback['success']:
              reflection = VLM.generate(
                  prompt="Why did the action fail? What to do next?"
              )
              # è¿”å›: "<Reflection> The navigation failed..."
              trajectory.append(reflection)
          
       g) ä¿å­˜
          trajectory.append({
              "observation": image,
              "action": action,
              "reward": feedback['reward']
          })

4ï¸âƒ£ è¾“å‡ºè½¨è¿¹
   {
       "scene": "FloorPlan1",
       "tasktype": "single_search",
       "taskname": "Find the Apple in the room.",
       "trajectory": [
           "<Observation> I see a kitchen...",
           "<Thought> The apple is likely on...",
           "<Decision> I should navigate...",
           "..."
       ],
       "images": [
           "path/to/image_0.png",
           "path/to/image_1.png",
           ...
       ]
   }
```

---

## ğŸ”‘ VLM é…ç½®åœ¨å“ªé‡Œï¼Ÿ

### 1ï¸âƒ£ API Key é…ç½®

**æ–‡ä»¶ä½ç½®**ï¼š
```
z:\Code_Windows\embodied_reasoner\data_engine\VLMCallapi_keys.py
```

**å½“å‰å†…å®¹** (ä¸ºç©º)ï¼š
```python
api_keys=[  
    # please add your api keys here
]
```

### 2ï¸âƒ£ å¦‚ä½•ä¿®æ”¹ï¼Ÿ

#### æ–¹æ¡ˆAï¼šç›´æ¥æ·»åŠ key
```python
# VLMCallapi_keys.py
api_keys = [
    "sk-proj-xxxxxxxxxxxxx",  # ChatGPT API key
    "sk-proj-yyyyyyyyyyyyy",  # å¤‡ç”¨key
]
```

#### æ–¹æ¡ˆBï¼šä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰
```python
# VLMCallapi_keys.py
import os

api_keys = [
    os.getenv("OPENAI_API_KEY"),
    os.getenv("OPENAI_API_KEY_BACKUP"),
]
```

ç„¶ååœ¨ç»ˆç«¯è®¾ç½®ï¼š
```bash
export OPENAI_API_KEY="sk-proj-xxxxx"
```

### 3ï¸âƒ£ VLM API è°ƒç”¨ä»£ç 

**æ–‡ä»¶ä½ç½®**ï¼š
```
z:\Code_Windows\embodied_reasoner\data_engine\vlmCall.py
```

**æ ¸å¿ƒä»£ç **ï¼š
```python
class VLMAPI:
    def __init__(self, model):
        self.model = model  # "gpt-4o-2024-11-20"
    
    def vlm_request(self, system_text, user_text, image_path1=None, max_tokens=1500):
        """
        è°ƒç”¨VLMæ¨¡å‹ç”Ÿæˆæ€ç»´
        """
        # 1. ç¼–ç å›¾åƒä¸ºbase64
        if image_path1:
            base64_image = self.encode_image(image_path1)
        
        # 2. æ„é€ æ¶ˆæ¯ä½“
        messages = [
            {
                "role": "system",
                "content": system_text
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_text},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                            "detail": "low"
                        }
                    }
                ]
            }
        ]
        
        # 3. æ„é€ è¯·æ±‚
        payload = json.dumps({
            "model": self.model,
            "stream": False,
            "messages": messages,
            "temperature": 0.9,
            "max_tokens": max_tokens
        })
        
        # 4. å‘é€è¯·æ±‚åˆ°OpenAIå…¼å®¹çš„API
        conn = http.client.HTTPSConnection("us.ifopen.ai")  # â† æ³¨æ„ï¼šè¿™ä¸æ˜¯å®˜æ–¹OpenAIï¼
        headers = {
            'Accept': 'application/json',
            'Authorization': 'Bearer ' + api_key,
            'Content-Type': 'application/json'
        }
        
        conn.request("POST", "/v1/chat/completions", payload, headers)
        res = conn.getresponse()
        data = json.loads(res.read().decode("utf-8"))
        
        # 5. æå–å“åº”
        content = data["choices"][0]["message"]["content"]
        return content
```

### 4ï¸âƒ£ å¦‚ä½•ä¿®æ”¹APIç«¯ç‚¹ï¼Ÿ

**é‡è¦å‘ç°**ï¼šå½“å‰ä»£ç ä½¿ç”¨ **éå®˜æ–¹çš„ OpenAI å…¼å®¹ API**ï¼

```python
# å½“å‰ä»£ç 
conn = http.client.HTTPSConnection("us.ifopen.ai")  # ç¬¬ä¸‰æ–¹æœåŠ¡

# æ”¹ä¸ºå®˜æ–¹OpenAI
conn = http.client.HTTPSConnection("api.openai.com")

# æˆ–æ”¹ä¸ºæœ¬åœ°éƒ¨ç½²
conn = http.client.HTTPSConnection("localhost:8000")
```

### 5ï¸âƒ£ o1StyleGenerate.py ä¸­çš„ä½¿ç”¨

```python
class O1StyleGenerate:
    def __init__(self, controller, scene, ..., model="gpt-4o-2024-11-20"):
        self.model = model  # â† æ¨¡å‹åç§°
        
    def generate_selfObs(self, image_path):
        """ç”Ÿæˆè‡ªæˆ‘è§‚å¯Ÿ"""
        llmapi = VLMAPI(self.model)
        selfobservation = llmapi.vlm_request(
            systext="You are a mobile robot...",
            usertext="Describe visible objects...",
            image_path1=image_path
        )
        return selfobservation
```

**åœ¨ä¸»ç¨‹åºä¸­æ›´æ”¹æ¨¡å‹**ï¼š
```python
# o1StyleGenerate.py ä¸»ç¨‹åº
if __name__ == "__main__":
    model = "gpt-4o-2024-11-20"  # â† æ”¹è¿™é‡Œ
    # æˆ–æ”¹ä¸º
    model = "gpt-4-turbo"
    model = "gpt-4"
    model = "claude-3-vision"  # å¦‚æœæ”¯æŒçš„è¯
```

---

## å®Œæ•´æ‰§è¡Œæµç¨‹å›¾

```
TaskGenerate.py (ä¸éœ€è¦VLM)
    â†“
    è¾“å…¥: AI2THORåœºæ™¯å…ƒæ•°æ® + pick_up_and_put.json
    â†“
    â””â”€â†’ single_search() éå†å¯¹è±¡ â†’ è¿‡æ»¤æ¡ä»¶ â†’ ç”Ÿæˆä»»åŠ¡JSON
    â””â”€â†’ single_pickup() ç±»ä¼¼é€»è¾‘
    â””â”€â†’ ordered_pickup_two_object_and_put() å¤æ‚ç»„åˆ
    â†“
    è¾“å‡º: {task_type}_task_metadata/{scene}.json
         [
             {"taskname": "Find Apple", "actions": [...]},
             {"taskname": "Pick up Plate", "actions": [...]},
             ...
         ]
    â†“
    â†“
o1StyleGenerate.py (éœ€è¦VLM)
    â†“
    è¾“å…¥: ä»»åŠ¡å…ƒæ•°æ® JSON + AI2THOR åœºæ™¯
    â†“
    for each task:
        â”œâ”€ åˆå§‹åŒ–è™šæ‹Ÿç¯å¢ƒ
        â”œâ”€ for each step:
        â”‚   â”œâ”€ æ•è·å›¾åƒ
        â”‚   â”œâ”€ è°ƒç”¨VLMç”Ÿæˆæ€ç»´ [éœ€è¦API key]
        â”‚   â”œâ”€ æ‰§è¡Œè¡ŒåŠ¨
        â”‚   â”œâ”€ ä¿å­˜è½¨è¿¹ + å›¾åƒ
        â”‚   â””â”€ æ£€æŸ¥æˆåŠŸ/å¤±è´¥
        â””â”€ è¾“å‡ºè½¨è¿¹JSON
    â†“
    è¾“å‡º: {scene}/{task_type}/trajectory_0.json
         {
             "scene": "FloorPlan1",
             "trajectory": ["<Observation>...", "<Thought>...", ...],
             "images": ["image_0.png", "image_1.png", ...],
             "reward": 10
         }
```

---

## å…³é”®å¯¹æ¯”è¡¨

| ç»„ä»¶ | éœ€è¦VLM? | è¾“å…¥ | è¾“å‡º | æ–‡ä»¶ |
|------|---------|------|------|------|
| **taskgenerate/** | âŒ | (æ— ) | åœºæ™¯å…ƒæ•°æ® + ç‰©ä½“å…¼å®¹æ€§ | metadata.json, pick_up_and_put.json |
| **TaskGenerate.py** | âŒ | åœºæ™¯å…ƒæ•°æ® | ä»»åŠ¡æ¨¡æ¿ + å…³é”®è¡ŒåŠ¨ | *_task_metadata/*.json |
| **o1StyleGenerate.py** | âœ… VLMå¿…éœ€ | ä»»åŠ¡å…ƒæ•°æ® + è™šæ‹Ÿç¯å¢ƒ | å®Œæ•´è½¨è¿¹ + æ€ç»´ + å›¾åƒ | trajectory_*.json + images/ |
| **VLMCallapi_keys.py** | âœ… API key | (æ— ) | OpenAI API keys | api_keys = [...] |
| **vlmCall.py** | âœ… HTTPå®¢æˆ·ç«¯ | æç¤ºè¯ + å›¾åƒ | VLMå“åº” | VLMAPI ç±» |

---

## è®¾ç½®å®Œæ•´æŒ‡å—

### Step 1: è·å–API Key
```bash
# ä» https://platform.openai.com/api-keys è·å–
# æˆ–ä½¿ç”¨å…¶ä»–VLMä¾›åº”å•†çš„key
```

### Step 2: é…ç½®API Key
```python
# VLMCallapi_keys.py
api_keys = [
    "sk-proj-your-key-here"
]
```

### Step 3: (å¯é€‰) ä¿®æ”¹APIç«¯ç‚¹
```python
# vlmCall.py ä¸­æœç´¢ "us.ifopen.ai"
# æ”¹ä¸ºä½ çš„APIç«¯ç‚¹ (å®˜æ–¹OpenAI æˆ–æœ¬åœ°éƒ¨ç½²)
```

### Step 4: è¿è¡Œæ•°æ®ç”Ÿæˆ
```bash
# 1. ç”Ÿæˆä»»åŠ¡
cd data_engine
python TaskGenerate.py

# 2. ç”Ÿæˆæ€ç»´è½¨è¿¹ (éœ€è¦ç½‘ç»œå’ŒAPI key)
python o1StyleGenerate.py
```

---

## å¸¸è§é—®é¢˜

### Q: TaskGenerate.py ä¸ºä»€ä¹ˆä¸éœ€è¦VLM?
**A**: å®ƒåªåš**é€»è¾‘è¿‡æ»¤**ï¼Œä¸éœ€è¦"æ€è€ƒ"ã€‚å°±åƒä¸€ä¸ªæ•°æ®åº“æŸ¥è¯¢ï¼š
- æ¡ä»¶ï¼šå¯æ‹¿èµ·? âœ“ åœ¨å®¹å™¨é‡Œ? âœ“ â†’ ç”Ÿæˆä»»åŠ¡

### Q: o1StyleGenerate.py ä¸ºä»€ä¹ˆéœ€è¦VLM?
**A**: å› ä¸ºå®ƒéœ€è¦ç”Ÿæˆ**çœŸå®æ¨ç†è¿‡ç¨‹**ï¼š
- "ä¸ºä»€ä¹ˆè‹¹æœå¯èƒ½åœ¨æŸå¤„?" â†’ VLMæ€è€ƒ
- "ä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ?" â†’ VLMå†³ç­–
- è¿™ä¸èƒ½é è§„åˆ™å®Œæˆ

### Q: taskgenerate/ ä¸­çš„metadata.json æ˜¯æ€ä¹ˆç”Ÿæˆçš„?
**A**: æ¥è‡ªAI2THORæ¨¡æ‹Ÿå™¨çš„ `controller.last_event.metadata`
```python
# utils.py
def get_scene_metadata(scene):
    controller = Controller(..., scene=scene)
    metadata = controller.last_event.metadata
    save_data_to_json(metadata, f"taskgenerate/{room}/FloorPlan/{scene}/metadata.json")
```

### Q: å¦‚æœæ²¡æœ‰API key å¯ä»¥è¿è¡Œå—?
**A**: 
- âœ… TaskGenerate.py å¯ä»¥
- âŒ o1StyleGenerate.py ä¸èƒ½
- å¯ä»¥ä½¿ç”¨æœ¬åœ°æ¨¡å‹å¦‚ Llama ä½œä¸ºæ›¿ä»£

### Q: èƒ½æ”¹æˆä½¿ç”¨å›½å†…æ¨¡å‹ï¼ˆå¦‚Qwenï¼‰å—?
**A**: å¯ä»¥ï¼æ”¹ vlmCall.py:
```python
class VLMAPI:
    def vlm_request(self, ...):
        if self.model.startswith("qwen"):
            conn = http.client.HTTPSConnection("api.alibabacloud.com")  # é˜¿é‡Œäº‘ç«¯ç‚¹
            # æ”¹APIè°ƒç”¨æ–¹å¼
```
